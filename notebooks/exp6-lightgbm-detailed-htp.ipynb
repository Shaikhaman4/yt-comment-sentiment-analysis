{"cells":[{"cell_type":"code","source":["!pip install mlflow\n","!pip install pyngrok\n","\n","\n","import mlflow\n","import mlflow.sklearn\n","\n","mlflow.set_experiment(\"Exp 6- LightGBM HP Tuning\")\n","\n","from google.colab import userdata\n","ngRoktoken=userdata.get('ngroktoen')\n","\n","get_ipython().system_raw('mlflow ui --port 2000 &')\n","mlflow.set_tracking_uri('http://localhost:2000')\n","from pyngrok import ngrok\n","ngrok.set_auth_token(ngRoktoken)\n","\n","public_url=ngrok.connect(2000).public_url\n","print('mlflow ui url: ', public_url)"],"metadata":{"id":"cLRApJu2sKgm"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10209,"status":"ok","timestamp":1750688478625,"user":{"displayName":"Aman Shaikh","userId":"02126252817276980688"},"user_tz":-330},"id":"gJRLAjdOKd8i","outputId":"8a610e37-a165-43fa-fa4c-252ef47c2775"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting optuna\n","  Downloading optuna-4.4.0-py3-none-any.whl.metadata (17 kB)\n","Collecting alembic>=1.5.0 (from optuna)\n","  Downloading alembic-1.16.2-py3-none-any.whl.metadata (7.3 kB)\n","Collecting colorlog (from optuna)\n","  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n","Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.41)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n","Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n","Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.14.0)\n","Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.3)\n","Downloading optuna-4.4.0-py3-none-any.whl (395 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m395.9/395.9 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading alembic-1.16.2-py3-none-any.whl (242 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.7/242.7 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n","Installing collected packages: colorlog, alembic, optuna\n","Successfully installed alembic-1.16.2 colorlog-6.9.0 optuna-4.4.0\n"]}],"source":["!pip install optuna\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":536,"status":"ok","timestamp":1750688479187,"user":{"displayName":"Aman Shaikh","userId":"02126252817276980688"},"user_tz":-330},"id":"ECd_9jLXKWlH","outputId":"16dcf8b4-92c0-4a84-83bb-d59cdbc054c2"},"outputs":[{"data":{"text/plain":["(36662, 2)"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["import pandas as pd\n","df=pd.read_csv('reddit_preprocessing.csv').dropna()\n","df.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Hj4T5YQaGsmS"},"outputs":[],"source":["import optuna\n","from imblearn.over_sampling import SMOTE\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, classification_report\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","import pandas as pd\n","from lightgbm import LGBMClassifier\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4CZCILp6KQiI"},"outputs":[],"source":["# Step 1: Remap the class labels from [-1, 0, 1] to [2, 0, 1]\n","df['category'] = df['category'].map({-1: 2, 0: 0, 1: 1})\n","\n","# Step 2: Remove rows where the target label (category) are NAN\n","df = df.dropna(subset=['category'])\n","\n","# Step 3: TF-IDF vectorizer setup\n","ngram_range = (1, 3)  # trigram\n","max_features = 1000   # set max_features to 1000\n","vectorizer = TfidfVectorizer(ngram_range=ngram_range, max_features=max_features)\n","X = vectorizer.fit_transform(df['clean_comment'])\n","y = df['category']\n","\n","# Step 4: Apply SMOTE to handle class imbalance\n","smote = SMOTE(random_state=42)\n","X_resampled, y_resampled = smote.fit_resample(X, y)\n","\n","# Step 5: Train-test split\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X_resampled, y_resampled, test_size=0.2, random_state=42, stratify=y_resampled\n",")\n","\n","\n","\n","# Function to log results in MLflow\n","def log_mlflow(model_name, model, X_train, X_test, y_train, y_test, params, trial_number):\n","    with mlflow.start_run():\n","        # Log model type and trial number\n","        mlflow.set_tag(\"mlflow.runName\", f\"Trial_{trial_number}_{model_name}_SMOTE_TFIDF_Trigrams\")\n","        mlflow.set_tag(\"experiment_type\", \"algorithm_comparison\")\n","\n","        # Log algorithm name as a parameter\n","        mlflow.log_param(\"algo_name\", model_name)\n","\n","        # Log hyperparameters\n","        for key, value in params.items():\n","            mlflow.log_param(key, value)\n","\n","        # Train model\n","        model.fit(X_train, y_train)\n","        y_pred = model.predict(X_test)\n","\n","        # Log accuracy\n","        accuracy = accuracy_score(y_test, y_pred)\n","        mlflow.log_metric(\"accuracy\", accuracy)\n","\n","        # Log classification report\n","        classification_rep = classification_report(y_test, y_pred, output_dict=True)\n","        for label, metrics in classification_rep.items():\n","            if isinstance(metrics, dict):\n","                for metric, value in metrics.items():\n","                    mlflow.log_metric(f\"{label}_{metric}\", value)\n","\n","        # Log the model\n","        mlflow.sklearn.log_model(model, f\"{model_name}_model\")\n","\n","    return accuracy\n","\n","\n","# Step 6: Optuna objective function for LightGBM\n","def objective_lightgbm(trial):\n","    # Hyperparameter space to explore\n","    n_estimators = trial.suggest_int(\"n_estimators\", 100, 1000)\n","    learning_rate = trial.suggest_float(\"learning_rate\", 1e-4, 1e-1, log=True)\n","    max_depth = trial.suggest_int(\"max_depth\", 3, 15)\n","    num_leaves = trial.suggest_int(\"num_leaves\", 20, 150)\n","    min_child_samples = trial.suggest_int(\"min_child_samples\", 10, 100)\n","    colsample_bytree = trial.suggest_float(\"colsample_bytree\", 0.5, 1.0)\n","    subsample = trial.suggest_float(\"subsample\", 0.5, 1.0)\n","    reg_alpha = trial.suggest_float(\"reg_alpha\", 1e-4, 10.0, log=True)   # L1 regularization\n","    reg_lambda = trial.suggest_float(\"reg_lambda\", 1e-4, 10.0, log=True) # L2 regularization\n","\n","    # Log trial parameters\n","    params = {\n","        'n_estimators': n_estimators,\n","        'learning_rate': learning_rate,\n","        'max_depth': max_depth,\n","        'num_leaves': num_leaves,\n","        'min_child_samples': min_child_samples,\n","        'colsample_bytree': colsample_bytree,\n","        'subsample': subsample,\n","        'reg_alpha': reg_alpha,\n","        'reg_lambda': reg_lambda\n","    }\n","\n","    # Create LightGBM model\n","    model = LGBMClassifier(\n","        n_estimators=n_estimators,\n","        learning_rate=learning_rate,\n","        max_depth=max_depth,\n","        num_leaves=num_leaves,\n","        min_child_samples=min_child_samples,\n","        colsample_bytree=colsample_bytree,\n","        subsample=subsample,\n","        reg_alpha=reg_alpha,\n","        reg_lambda=reg_lambda,\n","        random_state=42\n","    )\n","\n","    # Log each trial as a separate run in MLflow\n","    accuracy = log_mlflow(\"LightGBM\", model, X_train, X_test, y_train, y_test, params, trial.number)\n","\n","    return accuracy\n","\n","\n","# Step 7: Run Optuna for LightGBM, log the best model, and plot the importance of each parameter\n","def run_optuna_experiment():\n","    study = optuna.create_study(direction=\"maximize\")\n","    study.optimize(objective_lightgbm, n_trials=100)  # Increased to 100 trials\n","\n","    # Get the best parameters\n","    best_params = study.best_params\n","    best_model = LGBMClassifier(\n","        n_estimators=best_params[\"n_estimators\"],\n","        learning_rate=best_params[\"learning_rate\"],\n","        max_depth=best_params[\"max_depth\"],\n","        num_leaves=best_params[\"num_leaves\"],\n","        min_child_samples=best_params[\"min_child_samples\"],\n","        colsample_bytree=best_params[\"colsample_bytree\"],\n","        subsample=best_params[\"subsample\"],\n","        reg_alpha=best_params[\"reg_alpha\"],\n","        reg_lambda=best_params[\"reg_lambda\"],\n","        random_state=42\n","    )\n","\n","    # Log the best model with MLflow and print the classification report\n","    log_mlflow(\"LightGBM\", best_model, X_train, X_test, y_train, y_test, best_params, \"Best\")\n","\n","    # Plot parameter importance\n","    optuna.visualization.plot_param_importances(study).show()\n","\n","    # Plot optimization history\n","    optuna.visualization.plot_optimization_history(study).show()\n","\n","\n","# Run the experiment for LightGBM\n","run_optuna_experiment()\n"]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMqCYC2gr5OW2k3/u2xbVzT"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}