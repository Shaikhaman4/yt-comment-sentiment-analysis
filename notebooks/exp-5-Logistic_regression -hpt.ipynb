{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOxhpGvCMQjbm8VboNQp7zb"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install mlflow\n","!pip install pyngrok\n","\n","\n","import mlflow\n","import mlflow.sklearn\n","\n","mlflow.set_experiment(\"Exp 5- ML Algos with HP Tuning\")\n","\n","from google.colab import userdata\n","ngRoktoken=userdata.get('ngroktoen')\n","\n","get_ipython().system_raw('mlflow ui --port 2000 &')\n","mlflow.set_tracking_uri('http://localhost:2000')\n","from pyngrok import ngrok\n","ngrok.set_auth_token(ngRoktoken)\n","\n","public_url=ngrok.connect(2000).public_url\n","print('mlflow ui url: ', public_url)"],"metadata":{"id":"6GfFRKMDrSES"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install optuna\n"],"metadata":{"id":"6cgF7sHIq-XH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df=pd.read_csv('reddit_preprocessing.csv').dropna(subset=['clean_comment'])\n","df.shape"],"metadata":{"id":"16pmZPyXq-Tv"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"01loZkttq6q3"},"outputs":[],"source":["# =================== Imports ===================\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import mlflow\n","import mlflow.sklearn\n","import optuna\n","\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, classification_report\n","from sklearn.linear_model import LogisticRegression\n","from imblearn.over_sampling import SMOTE\n","from mlflow.models.signature import infer_signature\n","# ==============================================\n","\n","# Step 1: Remap the class labels from [-1, 0, 1] to [2, 0, 1]\n","df['category'] = df['category'].map({-1: 2, 0: 0, 1: 1})\n","\n","# Step 2: Remove rows with NaN category values (due to mapping)\n","df = df.dropna(subset=['category'])\n","\n","# Step 3: TF-IDF vectorizer setup\n","ngram_range = (1, 3)  # trigram\n","max_features = 1000   # set max_features to 1000\n","vectorizer = TfidfVectorizer(ngram_range=ngram_range, max_features=max_features)\n","X = vectorizer.fit_transform(df['clean_comment'])\n","y = df['category']\n","\n","# Step 4: Apply SMOTE to handle class imbalance\n","smote = SMOTE(random_state=42)\n","X_resampled, y_resampled = smote.fit_resample(X, y)\n","\n","# Step 5: Train-test split\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X_resampled, y_resampled, test_size=0.2, random_state=42, stratify=y_resampled\n",")\n","\n","# Function to log results in MLflow\n","def log_mlflow(model_name, model, X_train, X_test, y_train, y_test):\n","    with mlflow.start_run():\n","        # log model type\n","        mlflow.set_tag(\"mlflow.runName\", f\"{model_name}_SMOTE_TFIDF_Trigrams\")\n","        mlflow.set_tag(\"experiment_type\", \"algorithm_comparison\")\n","\n","        # log algorithm name as a parameter\n","        mlflow.log_param(\"algo_name\", model_name)\n","\n","        # train model\n","        model.fit(X_train, y_train)\n","        y_pred = model.predict(X_test)\n","\n","        # log accuracy\n","        accuracy = accuracy_score(y_test, y_pred)\n","        mlflow.log_metric(\"accuracy\", accuracy)\n","\n","        # log classification report\n","        classification_rep = classification_report(y_test, y_pred, output_dict=True)\n","        for label, metrics in classification_rep.items():\n","            if isinstance(metrics, dict):\n","                for metric, value in metrics.items():\n","                    mlflow.log_metric(f\"{label}_{metric}\", value)\n","\n","        # log the model with input_example and signature\n","        input_example = X_test[:1]\n","        pred_example = model.predict(input_example)\n","        signature = infer_signature(input_example, pred_example)\n","\n","        mlflow.sklearn.log_model(\n","            sk_model=model,\n","            artifact_path=f\"{model_name}_model\",\n","            input_example=input_example,\n","            signature=signature\n","        )\n","\n","# Step 6: Optuna objective function for Logistic Regression\n","def objective_logreg(trial):\n","    C = trial.suggest_float('C', 0.01, 10.0, log=True)\n","    penalty = trial.suggest_categorical('penalty', ['l2', 'none'])\n","\n","    # Only solvers compatible with multi-class and selected penalties\n","    model = LogisticRegression(\n","        C=C,\n","        penalty=penalty,\n","        solver='saga' if penalty == 'l2' else 'lbfgs',\n","        max_iter=1000,\n","        random_state=42,\n","        multi_class='multinomial'\n","    )\n","\n","    return accuracy_score(y_test, model.fit(X_train, y_train).predict(X_test))\n","\n","# Step 7: Run Optuna study and log best model only\n","def run_optuna_experiment():\n","    study = optuna.create_study(direction=\"maximize\")\n","    study.optimize(objective_logreg, n_trials=30)\n","\n","    # get the best parameters and log only the best model\n","    best_params = study.best_params\n","    best_model = LogisticRegression(\n","        C=best_params['C'],\n","        penalty=best_params['penalty'],\n","        solver='saga' if best_params['penalty'] == 'l2' else 'lbfgs',\n","        max_iter=1000,\n","        random_state=42,\n","        multi_class='multinomial'\n","    )\n","\n","    # log the best model with mlflow, passing the algo_name as 'LogisticRegression'\n","    log_mlflow(\"LogisticRegression\", best_model, X_train, X_test, y_train, y_test)\n","\n","# Run the full Logistic Regression tuning and logging experiment\n","run_optuna_experiment()\n"]}]}